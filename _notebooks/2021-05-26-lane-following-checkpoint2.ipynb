{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lane Following using Comma AI dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "[Comma AI dataset](https://github.com/commaai/comma2k19) is used to train the model. This dataset has over 33 hours of\n",
    "commute in California's highway. Dataset is divided into 95% training, 5% validation and 5% test set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "Convolutional neural network defined in [NVIDIA's PilotNet](https://arxiv.org/abs/1604.07316) is used as model architecture.\n",
    "![PilotNet](images/pilotnet.jpg \"Credit: https://twitter.com/haltakov/status/1384192583597912065\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "\n",
    "Model is trained until validation loss fails to improve for 10 epochs. Mean absolute error (MAE) is used  as loss function\n",
    "as it proved to work better compared to mean square error (MSE) loss as it magnifies errors with big steering angles too\n",
    "much.\n",
    "\n",
    "Big effort was needed to speed up training speed as training on video files is very slow, this is magnified with the need\n",
    "to access frames randomly during training. I tried to speed up the processing by using [NVIDIA DALI](https://docs.nvidia.com/deeplearning/dali/user-guide/docs),\n",
    "but reading video frames was still bottleneck and not GPU. Best performance was achived by extracting all frame from video\n",
    "files into JPG files with reduced resolution and training model using these."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "\n",
    "Model performance using videos from validation dataset:\n",
    "> youtube: https://youtu.be/iR3qkDQD_Pk\n",
    "> youtube: https://youtu.be/p1wjzHW8HCY"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model performed also relatively well using out of distribution videos from UT dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Grad-CAM](https://arxiv.org/abs/1610.02391) paper introduces technique for producing \"visual explanations\" for decisions\n",
    "from a large class of CNN-based models. There is great [pytorch implementation](https://github.com/jacobgil/pytorch-grad-cam)\n",
    "implemented for class prediction, which is modified to work with regression problem to display activation maps.\n",
    "\n",
    "First layer seems to provides best information. Model seems to be mostly concentrating on road markings, ground under\n",
    "other cars and sides of the road:\n",
    "> youtube: https://youtu.be/hlQyDc7xGMc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learnings\n",
    "- Most effort will go preparing data pipeline and not tuning model itself\n",
    "- Gradient based visualisation can provide insights into how model works\n",
    "\n",
    "## Conclusions"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}